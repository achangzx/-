import torch
import torchvision
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
#下载数据集
my_train=torchvision.datasets.CIFAR10('../train',train=True,transform=torchvision.transforms.ToTensor(),download=True)
my_test=torchvision.datasets.CIFAR10('../test',train=False,transform=torchvision.transforms.ToTensor(),download=True)

#加载数据集
my_train_load=DataLoader(my_train,batch_size=64,shuffle=False)
my_test_load=DataLoader(my_test,batch_size=64,shuffle=False)
print('训练集的长度为{}'.format(len(my_train)))
print('测试集的长度为{}'.format(len(my_test)))


#导入我们的神经网络
moudle=torchvision.models.vgg16(pretrained=False)
moudle.classifier.add_module('7',Linear(1000,10,))
moudle.cuda()



#可视化我们损失函数
loss_ff = nn.CrossEntropyLoss() 
loss_ff=loss_ff.cuda()
a=SummaryWriter('my_logs')

#对训练集开始训练
optim=torch.optim.SGD(moudle.parameters(),lr=0.01)
for i in range(20):
    J=0
    for imgs,target in my_train_load:
        imgs=imgs.cuda()
        target=target.cuda()
        imgs_train_load=moudle.forward(imgs)
        loss=loss_ff.forward(imgs_train_load,target)
        optim.zero_grad()
        loss.backward()
        optim.step()
        J=J+loss
    a.add_scalar('train_loss',loss,i)
    print('--------------第{}轮训练已经开始--------------'.format(i+1))
    print('第{}轮训练训练集的损失函数为{}'.format(i+1,J))
    #对每一轮的训练结果都进行测试



    with torch.no_grad():               #要保证我们的测试集是没有被优化的
        test_loss=0
        rigt_number=0
        for imgs1,target1 in my_test_load:
            imgs1=imgs1.cuda()
            target1=target1.cuda()
            imgs1_test_load=moudle.forward(imgs1)
            loss1=loss_ff.forward(imgs1_test_load,target1)
            test_loss=test_loss+loss1
          #定义在每一轮训练下的每一个bathsize正确的个数
            rigt_number=rigt_number+(imgs1_test_load.argmax(1)==target1).sum()
        rigt_rate=rigt_number/(len(my_test))
       #可视化损失函数随着训练的轮数的变化
        a.add_scalar('test_loss', loss1, i)
        a.close()


        print('对第{}轮训练结果进行测试'.format(i+1))
        print('测试集损失函数为{}'.format(test_loss))
        print('测试集的正确率为{}'.format(rigt_rate))

运行结果为：
Files already downloaded and verified
Files already downloaded and verified
训练集的长度为50000
测试集的长度为10000
--------------第1轮训练已经开始--------------
第1轮训练训练集的损失函数为1797.98974609375
对第1轮训练结果进行测试
测试集损失函数为357.8056945800781
测试集的正确率为0.1046999990940094
--------------第2轮训练已经开始--------------
第2轮训练训练集的损失函数为1695.595458984375
对第2轮训练结果进行测试
测试集损失函数为330.626953125
测试集的正确率为0.23899999260902405
--------------第3轮训练已经开始--------------
第3轮训练训练集的损失函数为1557.518310546875
对第3轮训练结果进行测试
测试集损失函数为287.5889587402344
测试集的正确率为0.32009997963905334
--------------第4轮训练已经开始--------------
第4轮训练训练集的损失函数为1385.23046875
对第4轮训练结果进行测试
测试集损失函数为285.3016357421875
测试集的正确率为0.2953000068664551
--------------第5轮训练已经开始--------------
第5轮训练训练集的损失函数为1241.8748779296875
对第5轮训练结果进行测试
测试集损失函数为267.2191162109375
测试集的正确率为0.3659999966621399
--------------第6轮训练已经开始--------------
第6轮训练训练集的损失函数为1128.71435546875
对第6轮训练结果进行测试
测试集损失函数为257.6865539550781
测试集的正确率为0.383899986743927
--------------第7轮训练已经开始--------------
第7轮训练训练集的损失函数为1030.5283203125
对第7轮训练结果进行测试
测试集损失函数为219.92306518554688
测试集的正确率为0.47349998354911804
--------------第8轮训练已经开始--------------
第8轮训练训练集的损失函数为933.6332397460938
对第8轮训练结果进行测试
测试集损失函数为208.38453674316406
测试集的正确率为0.5300999879837036
--------------第9轮训练已经开始--------------
第9轮训练训练集的损失函数为841.6065673828125
对第9轮训练结果进行测试
测试集损失函数为198.15187072753906
测试集的正确率为0.5615999698638916
--------------第10轮训练已经开始--------------
第10轮训练训练集的损失函数为756.2742919921875
对第10轮训练结果进行测试
测试集损失函数为179.75851440429688
测试集的正确率为0.5985999703407288
--------------第11轮训练已经开始--------------
第11轮训练训练集的损失函数为675.7687377929688
对第11轮训练结果进行测试
测试集损失函数为209.083984375
测试集的正确率为0.5497999787330627
--------------第12轮训练已经开始--------------
第12轮训练训练集的损失函数为601.3908081054688
对第12轮训练结果进行测试
测试集损失函数为183.90928649902344
测试集的正确率为0.6148999929428101
--------------第13轮训练已经开始--------------
第13轮训练训练集的损失函数为530.9391479492188
对第13轮训练结果进行测试
测试集损失函数为206.69085693359375
测试集的正确率为0.6006999611854553
--------------第14轮训练已经开始--------------
第14轮训练训练集的损失函数为466.26678466796875
对第14轮训练结果进行测试
测试集损失函数为182.01466369628906
测试集的正确率为0.6444999575614929
--------------第15轮训练已经开始--------------
第15轮训练训练集的损失函数为411.200927734375
对第15轮训练结果进行测试
测试集损失函数为177.8555145263672
测试集的正确率为0.6703999638557434
--------------第16轮训练已经开始--------------
第16轮训练训练集的损失函数为351.7673034667969
对第16轮训练结果进行测试
测试集损失函数为199.656005859375
测试集的正确率为0.6459999680519104
--------------第17轮训练已经开始--------------
第17轮训练训练集的损失函数为304.62713623046875
对第17轮训练结果进行测试
测试集损失函数为210.45733642578125
测试集的正确率为0.6430000066757202
--------------第18轮训练已经开始--------------
第18轮训练训练集的损失函数为261.20703125
对第18轮训练结果进行测试
测试集损失函数为176.2052459716797
测试集的正确率为0.6983000040054321
--------------第19轮训练已经开始--------------
第19轮训练训练集的损失函数为219.91310119628906
对第19轮训练结果进行测试
测试集损失函数为203.1193389892578
测试集的正确率为0.6807000041007996
--------------第20轮训练已经开始--------------
第20轮训练训练集的损失函数为193.0343475341797
对第20轮训练结果进行测试
测试集损失函数为219.85971069335938
测试集的正确率为0.6786999702453613

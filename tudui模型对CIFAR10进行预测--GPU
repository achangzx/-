import torch
import torchvision
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
#下载数据集
my_train=torchvision.datasets.CIFAR10('../train',train=True,transform=torchvision.transforms.ToTensor(),download=True)
my_test=torchvision.datasets.CIFAR10('../test',train=False,transform=torchvision.transforms.ToTensor(),download=True)

#加载数据集
my_train_load=DataLoader(my_train,batch_size=64,shuffle=False)
my_test_load=DataLoader(my_test,batch_size=64,shuffle=False)
print('训练集的长度为{}'.format(len(my_train)))
print('测试集的长度为{}'.format(len(my_test)))


#导入我们的神经网络
class my_nn(nn.Module):
    def __init__(self):
        super(my_nn, self).__init__()
        self.mood=Sequential(Conv2d(3,32,5,padding=2),
                           MaxPool2d(2),
                           Conv2d(32,32,5,padding=2),
                           MaxPool2d(2),
                           Conv2d(32,64,5,padding=2),
                           MaxPool2d(2),
                           Flatten(),
                           Linear(1024,64),
                           Linear(64,10),
        )
        self.cov_layer1=Conv2d(3,32,5,padding=2)
        self.pool_layer1=MaxPool2d(2)
        self.cov_layer2=Conv2d(32,32,5,padding=2)
        self.pool_layer2=MaxPool2d(2)
        self.cov_layer3=Conv2d(32,64,5,padding=2)
        self.pool_layer3=MaxPool2d(2)
        self.flatten=Flatten()
        self.linear=Linear(1024,64)
        self.linear2 = Linear(64,10)
    def forward(self,x):
            x=self.mood(x)
            return x
moudle=my_nn()
moudle.cuda()



#可视化我们损失函数
loss_ff = nn.CrossEntropyLoss() 
loss_ff=loss_ff.cuda()
a=SummaryWriter('my_logs')

#对训练集开始训练
optim=torch.optim.SGD(moudle.parameters(),lr=0.01)
for i in range(20):
    J=0
    for imgs,target in my_train_load:
        imgs=imgs.cuda()
        target=target.cuda()
        imgs_train_load=moudle.forward(imgs)
        loss=loss_ff.forward(imgs_train_load,target)
        optim.zero_grad()
        loss.backward()
        optim.step()
        J=J+loss
    a.add_scalar('train_loss',loss,i)
    print('--------------第{}轮训练已经开始--------------'.format(i+1))
    print('第{}轮训练训练集的损失函数为{}'.format(i+1,J))
    #对每一轮的训练结果都进行测试



    with torch.no_grad():               #要保证我们的测试集是没有被优化的
        test_loss=0
        rigt_number=0
        for imgs1,target1 in my_test_load:
            imgs1=imgs1.cuda()
            target1=target1.cuda()
            imgs1_test_load=moudle.forward(imgs1)
            loss1=loss_ff.forward(imgs1_test_load,target1)
            test_loss=test_loss+loss1
          #定义在每一轮训练下的每一个bathsize正确的个数
            rigt_number=rigt_number+(imgs1_test_load.argmax(1)==target1).sum()
        rigt_rate=rigt_number/(len(my_test))
       #可视化损失函数随着训练的轮数的变化
        a.add_scalar('test_loss', loss1, i)
        a.close()


        print('对第{}轮训练结果进行测试'.format(i+1))
        print('测试集损失函数为{}'.format(test_loss))
        print('测试集的正确率为{}'.format(rigt_rate))



运行结果：
Files already downloaded and verified
Files already downloaded and verified
训练集的长度为50000
测试集的长度为10000
--------------第1轮训练已经开始--------------
第1轮训练训练集的损失函数为1707.9249267578125
对第1轮训练结果进行测试
测试集损失函数为317.8502502441406
测试集的正确率为0.2703000009059906
--------------第2轮训练已经开始--------------
第2轮训练训练集的损失函数为1446.438232421875
对第2轮训练结果进行测试
测试集损失函数为295.3059387207031
测试集的正确率为0.32760000228881836
--------------第3轮训练已经开始--------------
第3轮训练训练集的损失函数为1305.9102783203125
对第3轮训练结果进行测试
测试集损失函数为265.2309875488281
测试集的正确率为0.3893999755382538
--------------第4轮训练已经开始--------------
第4轮训练训练集的损失函数为1212.216064453125
对第4轮训练结果进行测试
测试集损失函数为251.27586364746094
测试集的正确率为0.421099990606308
--------------第5轮训练已经开始--------------
第5轮训练训练集的损失函数为1146.4554443359375
对第5轮训练结果进行测试
测试集损失函数为245.6009521484375
测试集的正确率为0.4316999912261963
--------------第6轮训练已经开始--------------
第6轮训练训练集的损失函数为1092.7369384765625
对第6轮训练结果进行测试
测试集损失函数为236.6722869873047
测试集的正确率为0.45170000195503235
--------------第7轮训练已经开始--------------
第7轮训练训练集的损失函数为1044.6617431640625
对第7轮训练结果进行测试
测试集损失函数为227.00311279296875
测试集的正确率为0.47999998927116394
--------------第8轮训练已经开始--------------
第8轮训练训练集的损失函数为998.2962036132812
对第8轮训练结果进行测试
测试集损失函数为216.4309844970703
测试集的正确率为0.5044000148773193
--------------第9轮训练已经开始--------------
第9轮训练训练集的损失函数为953.3656005859375
对第9轮训练结果进行测试
测试集损失函数为205.86734008789062
测试集的正确率为0.5295999646186829
--------------第10轮训练已经开始--------------
第10轮训练训练集的损失函数为911.8279418945312
对第10轮训练结果进行测试
测试集损失函数为197.57733154296875
测试集的正确率为0.5539000034332275
--------------第11轮训练已经开始--------------
第11轮训练训练集的损失函数为874.5136108398438
对第11轮训练结果进行测试
测试集损失函数为190.2892608642578
测试集的正确率为0.5684999823570251
--------------第12轮训练已经开始--------------
第12轮训练训练集的损失函数为841.1133422851562
对第12轮训练结果进行测试
测试集损失函数为185.18655395507812
测试集的正确率为0.5805000066757202
--------------第13轮训练已经开始--------------
第13轮训练训练集的损失函数为810.7158203125
对第13轮训练结果进行测试
测试集损失函数为181.56927490234375
测试集的正确率为0.5907999873161316
--------------第14轮训练已经开始--------------
第14轮训练训练集的损失函数为782.8809814453125
对第14轮训练结果进行测试
测试集损失函数为179.94862365722656
测试集的正确率为0.5947999954223633
--------------第15轮训练已经开始--------------
第15轮训练训练集的损失函数为757.197998046875
对第15轮训练结果进行测试
测试集损失函数为179.48077392578125
测试集的正确率为0.5968999862670898
--------------第16轮训练已经开始--------------
第16轮训练训练集的损失函数为733.3707275390625
对第16轮训练结果进行测试
测试集损失函数为178.78163146972656
测试集的正确率为0.6026999950408936
--------------第17轮训练已经开始--------------
第17轮训练训练集的损失函数为711.2781372070312
对第17轮训练结果进行测试
测试集损失函数为177.36749267578125
测试集的正确率为0.6085000038146973
--------------第18轮训练已经开始--------------
第18轮训练训练集的损失函数为690.3717041015625
对第18轮训练结果进行测试
测试集损失函数为176.3997802734375
测试集的正确率为0.6137999892234802
--------------第19轮训练已经开始--------------
第19轮训练训练集的损失函数为670.3895263671875
对第19轮训练结果进行测试
测试集损失函数为175.5928955078125
测试集的正确率为0.6175000071525574
--------------第20轮训练已经开始--------------
第20轮训练训练集的损失函数为651.088623046875
对第20轮训练结果进行测试
测试集损失函数为176.3011016845703
测试集的正确率为0.6193999648094177
